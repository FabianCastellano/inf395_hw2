{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfb51b70-95a7-4a7b-8a9f-262bb2cf6afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output\n",
    "import PIL as pl\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "834991b6-abde-4844-89d3-e45e41816839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "import numpy as np   \n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0769daa-55e1-4c56-b090-8c251e8d338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = hub.KerasLayer(\"https://tfhub.dev/adityakane2001/regnety600mf_feature_extractor/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e96e7a7-c6fe-40b7-b006-450becd0648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"./Train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebe55ecd-c37c-4487-af29-9a43fb9847db",
   "metadata": {},
   "outputs": [],
   "source": [
    "types = np.load(\"dict.npy\", allow_pickle = True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c25691b9-2964-4141-b412-b89c291e58f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3aa633a-abc8-4783-8fcb-1fa71ad91906",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tipo\"] = data[\"Expected\"].apply(lambda x : types[x.split(\" \")[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a8846f0-7ab6-4060-b157-f1fa7f296ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"animal\"] = data[\"Expected\"].apply(lambda x : types[x.split(\" \")[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "724756f0-9447-4d95-94ce-88b53f21ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(train_path):\n",
    "    if \"jpeg\" in file and \".\" not in file:\n",
    "        new = file.replace(\"jpeg\", \".jpeg\")\n",
    "        print(f\"Changing : {file} to {new}\")\n",
    "        os.rename(train_path + file, train_path + file.replace(\"jpeg\", \".jpeg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccf81a15-0cca-470c-bc38-8c2df1c71f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change(x):\n",
    "    if \"jpeg\" in x and \".\" not in x:\n",
    "        return x.replace(\"jpeg\", \".jpeg\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f70afb20-6d67-41ed-b598-f27cc78e91bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Id\"] = data[\"Id\"].apply(lambda x : change(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45560add-2aa0-4647-886e-b65155f00022",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b452709c-297d-4a38-9203-cb80fa6f647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index().drop(\"index\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be365fe8-ddc0-4ad0-a608-b7e8b34a040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = data.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c3795de-7631-4cc8-8cf8-09036ff59362",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cf180e8-43b7-4e7c-ac75-c02dcca06aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(l, columns = [\"Id\", \"Expected\", \"tipo\", \"animal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "186e11d7-1277-4faa-b196-3b3a4767b172",
   "metadata": {},
   "outputs": [],
   "source": [
    "del l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c386ee91-ff53-4dbf-bd7e-2112a3761c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_size = (224, 224)\n",
    "size = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b911fbd-02e3-41b1-8c2f-155e8c25a512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 3521 file of 3521\n"
     ]
    }
   ],
   "source": [
    "list_of_images = []\n",
    "for i, file in enumerate(data[\"Id\"]):\n",
    "    \n",
    "    print(f\"Loading {i + 1} file of {size}\")\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    image = pl.Image.open(train_path + file).resize(shape_size)\n",
    "    list_of_images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36f4e9a9-1f9e-4061-aa1e-f65b1428da60",
   "metadata": {},
   "outputs": [],
   "source": [
    "Images = np.zeros((len(data), shape_size[0], shape_size[1], 3), dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da0433a5-a64a-49fb-a048-36064d53e84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 3521 file of 3521\n"
     ]
    }
   ],
   "source": [
    "for i, image in enumerate(list_of_images):\n",
    "    print(f\"Loading {i + 1} file of {size}\")\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    try:\n",
    "        array = np.asarray(image) / 255\n",
    "        Images[i] = array\n",
    "    except:\n",
    "        array = (np.asarray(image).T[0 : 3] / 255).T\n",
    "        Images[i] = array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "634b0564-c8d8-4a65-b6f7-2b634092c8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "del list_of_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12808116-8126-4116-b825-2926ba6fd75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Buho', 'Mariposa', 'Caballo', 'Oso', 'Perro', 'Lobo', 'Cacique',\n",
       "       'Ganso', 'Conejo', 'Paloma', 'Cormoran', 'Iguana', 'Cisne',\n",
       "       'Lagarto', 'Leon', 'Pato', 'Elefante', 'Sapo', 'Lombriz',\n",
       "       'Tarantula', 'Cocodrilo', 'Tortuga', 'Salamandra', 'Cabra', 'Gato',\n",
       "       'Viuda negra', 'Tigre', 'Rana', 'Pavo', 'Camaleon', 'Serpiente',\n",
       "       'Saltamontes'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"animal\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07fca056-9bac-4d61-814b-3bb0c7ded931",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data[\"animal\"].unique():\n",
    "    data[col] = data[\"animal\"].apply(lambda x : int(x == col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1e9668f-5116-433d-9dff-9ef7fc0ed6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Images, data[data[\"animal\"].unique()], stratify = data[data[\"animal\"].unique()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eec39596-25f1-4657-b238-b6cebf81d872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner import Hyperband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc61c48-fbef-4da0-a05d-8fc215d00f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/classification/5\")\n",
    "])\n",
    "m.build([None, 224, 224, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a632c4c-f27c-4f76-a1dd-df6a9f2bd845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "  \n",
    "    hp_units1 = hp.Int('units1', min_value = 64, max_value = 512, step = 4)\n",
    "    hp_units2 = hp.Int('units2', min_value = 32, max_value = 512, step = 4)\n",
    "    hp_units3 = hp.Int('units3', min_value = 6, max_value = 512, step = 4)\n",
    "    \n",
    "    model.add(tf.keras.layers.RandomRotation(0.2))\n",
    "    model.add(tf.keras.layers.RandomFlip())\n",
    "    model.add(tf.keras.layers.GaussianNoise(0.1))\n",
    "    model.add(m)\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(units = hp_units1, activation = 'relu'))\n",
    "    model.add(tf.keras.layers.Dense(units = hp_units2, activation = 'relu'))\n",
    "    model.add(tf.keras.layers.Dense(units = hp_units3, activation = 'relu'))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
    "        loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics = tf.keras.metrics.BinaryAccuracy()\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cab55d83-1e99-4970-b99a-8e963a63e910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b83e8dbe-96a8-4886-bfe2-19e491e2d942",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = Hyperband(\n",
    "    build_model,\n",
    "    objective = \"val_loss\",\n",
    "    max_epochs = 15,\n",
    "    directory = 'tf_learning',\n",
    "    project_name = 'transfer_learning',\n",
    "    hyperband_iterations = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aba334b3-78b3-47b1-b6e2-5f1ad4e5134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(X_train, y_train, 32)\n",
    "test_gen = DataGenerator(X_test, y_test, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "edd11f9c-53a7-4509-96d6-afdf3ff8f1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 46 Complete [00h 00m 27s]\n",
      "val_loss: 0.1586228907108307\n",
      "\n",
      "Best val_loss So Far: 0.1404792219400406\n",
      "Total elapsed time: 00h 29m 00s\n",
      "\n",
      "Search: Running Trial #47\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "units1            |464               |496               \n",
      "units2            |208               |292               \n",
      "units3            |110               |106               \n",
      "learning_rate     |0.001             |0.001             \n",
      "tuner/epochs      |15                |15                \n",
      "tuner/initial_e...|5                 |5                 \n",
      "tuner/bracket     |2                 |2                 \n",
      "tuner/round       |2                 |2                 \n",
      "tuner/trial_id    |e56815c348fbc0a...|936c2e88e970026...\n",
      "\n",
      "Epoch 6/15\n",
      "83/83 [==============================] - 11s 102ms/step - loss: 0.1586 - binary_accuracy: 0.9627 - val_loss: 0.1432 - val_binary_accuracy: 0.9688\n",
      "Epoch 7/15\n",
      "83/83 [==============================] - 8s 94ms/step - loss: 0.1411 - binary_accuracy: 0.9688 - val_loss: 0.1421 - val_binary_accuracy: 0.9688\n",
      "Epoch 8/15\n",
      "83/83 [==============================] - 8s 92ms/step - loss: 0.1405 - binary_accuracy: 0.9688 - val_loss: 0.1417 - val_binary_accuracy: 0.9688\n",
      "Epoch 9/15\n",
      "83/83 [==============================] - 8s 94ms/step - loss: 0.1403 - binary_accuracy: 0.9688 - val_loss: 0.1413 - val_binary_accuracy: 0.9688\n",
      "Epoch 10/15\n",
      "83/83 [==============================] - 8s 94ms/step - loss: 0.1401 - binary_accuracy: 0.9688 - val_loss: 0.1412 - val_binary_accuracy: 0.9688\n",
      "Epoch 11/15\n",
      "83/83 [==============================] - 8s 94ms/step - loss: 0.1400 - binary_accuracy: 0.9688 - val_loss: 0.1411 - val_binary_accuracy: 0.9688\n",
      "Epoch 12/15\n",
      "83/83 [==============================] - 8s 93ms/step - loss: 0.1399 - binary_accuracy: 0.9688 - val_loss: 0.1410 - val_binary_accuracy: 0.9688\n",
      "Epoch 13/15\n",
      "83/83 [==============================] - 8s 91ms/step - loss: 0.1399 - binary_accuracy: 0.9688 - val_loss: 0.1412 - val_binary_accuracy: 0.9688\n",
      "Epoch 14/15\n",
      "35/83 [===========>..................] - ETA: 3s - loss: 0.1397 - binary_accuracy: 0.9688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.search(train_gen, epochs=10, validation_data = test_gen, callbacks = [tf.keras.callbacks.EarlyStopping(patience = 5, restore_best_weights = True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "59d44c8e-65f8-4950-a54e-6d686a2b9d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tuner.get_best_hyperparameters()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "729807ca-279f-4403-b58c-8322f4c063f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N1 : 496\n",
      "N2 : 292\n",
      "N3 : 106\n",
      "Lr : 0.001\n"
     ]
    }
   ],
   "source": [
    "print(f'N1 : {b.get(\"units1\")}\\nN2 : {b.get(\"units2\")}\\nN3 : {b.get(\"units3\")}\\nLr : {b.get(\"learning_rate\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7e1fe0c4-0772-4b32-b5fd-b34921c7fc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(hub_model):\n",
    "    \n",
    "    inputs = tf.keras.Input((None, None, 3))\n",
    "    \n",
    "    #Data Augmentation\n",
    "    rot =tf.keras.layers.RandomRotation(0.2)(inputs)\n",
    "    flip = tf.keras.layers.RandomFlip(\"horizontal\")(rot)\n",
    "    noise = tf.keras.layers.GaussianNoise(0.01)(flip)\n",
    "    bright = tf.keras.layers.RandomBrightness((-0.5, 0.5), (0, 1))(noise)\n",
    "    zoom = tf.keras.layers.RandomZoom((-0.5, 0.1), (-0.5, 0.1))(noise)\n",
    "    \n",
    "    x = hub_model(zoom)\n",
    "    \n",
    "    hidden_1 = tf.keras.layers.Dense(496, activation = \"relu\")(x)\n",
    "    drop_1 = tf.keras.layers.Dropout(0.3)(hidden_1)\n",
    "    hidden_2 = tf.keras.layers.Dense(292, activation = \"relu\")(drop_1)\n",
    "    drop_2 = tf.keras.layers.Dropout(0.3)(hidden_2)\n",
    "    hidden_3 = tf.keras.layers.Dense(106, activation = \"relu\")(drop_2)\n",
    "    drop_3 = tf.keras.layers.Dropout(0.3)(hidden_3)\n",
    "    \n",
    "    outputs = tf.keras.layers.Dense(1, activation = \"sigmoid\")(drop_3)\n",
    "    \n",
    "    model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3),\n",
    "        loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics = tf.keras.metrics.BinaryAccuracy()\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e886a978-493d-4959-b0ce-54e22e7d6a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train = np.zeros((2640 * 2, 224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7cecf9b5-ecdb-4cd3-9a43-72621dbccad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2640):\n",
    "    new_X_train[i] = X_train[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "820b908b-1b88-4b8f-90e2-077f592cb4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/classification/5\")\n",
    "])\n",
    "m.build([None, 224, 224, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5f2b0a2a-fea2-40cf-a269-49b05ebcda3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "acbfa408-f5da-49a0-a34f-f368f651a996",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = len(y_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a3e4fdaf-7443-4d17-891a-606a3dfdc9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Lombriz 31 of 32\n",
      "Epoch 1/500\n",
      "165/165 [==============================] - 17s 77ms/step - loss: 0.2340 - binary_accuracy: 0.9402 - val_loss: 0.0089 - val_binary_accuracy: 0.9966\n",
      "Epoch 2/500\n",
      "165/165 [==============================] - 12s 71ms/step - loss: 0.0223 - binary_accuracy: 0.9934 - val_loss: 0.0104 - val_binary_accuracy: 0.9966\n",
      "Epoch 3/500\n",
      "165/165 [==============================] - 12s 70ms/step - loss: 0.0164 - binary_accuracy: 0.9955 - val_loss: 0.0103 - val_binary_accuracy: 0.9966\n",
      "Epoch 4/500\n",
      "165/165 [==============================] - 12s 70ms/step - loss: 0.0153 - binary_accuracy: 0.9955 - val_loss: 0.0034 - val_binary_accuracy: 0.9989\n",
      "Epoch 5/500\n",
      "165/165 [==============================] - 11s 69ms/step - loss: 0.0150 - binary_accuracy: 0.9953 - val_loss: 0.0069 - val_binary_accuracy: 0.9966\n",
      "Epoch 6/500\n",
      "165/165 [==============================] - 12s 70ms/step - loss: 0.0101 - binary_accuracy: 0.9977 - val_loss: 0.0104 - val_binary_accuracy: 0.9955\n",
      "Epoch 7/500\n",
      "165/165 [==============================] - 11s 70ms/step - loss: 0.0102 - binary_accuracy: 0.9968 - val_loss: 0.0126 - val_binary_accuracy: 0.9955\n",
      "Epoch 8/500\n",
      "165/165 [==============================] - 11s 70ms/step - loss: 0.0165 - binary_accuracy: 0.9955 - val_loss: 0.0038 - val_binary_accuracy: 0.9977\n",
      "Epoch 9/500\n",
      "165/165 [==============================] - 12s 70ms/step - loss: 0.0125 - binary_accuracy: 0.9962 - val_loss: 0.0081 - val_binary_accuracy: 0.9955\n",
      "INFO:tensorflow:Assets written to: ./Models/Lombriz.obj\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Models/Lombriz.obj\\assets\n"
     ]
    }
   ],
   "source": [
    "for cant, col in enumerate(y_train.columns):\n",
    "    \n",
    "    final_model = make_model(m)\n",
    "    \n",
    "    filter_ = y_train[col] == 1\n",
    "    filtered = X_train[filter_]\n",
    "    n = len(filtered)\n",
    "    \n",
    "    for i in range(2640, 2640 * 2):\n",
    "        print(f\"Training {col} {cant} of {tot}\\nChanging {i + 1} of {2640 * 2}\")\n",
    "        clear_output(wait = True)\n",
    "        aux = tf.keras.preprocessing.image.random_zoom(filtered[i % n], (0.8, 1.5), 0, 1, 2)\n",
    "        aux = tf.keras.preprocessing.image.random_channel_shift(aux, 0.2, 2)\n",
    "        aux = tf.keras.preprocessing.image.random_rotation(aux, 180, 0, 1, 2)\n",
    "        new_X_train[i] = aux\n",
    "    print(f\"Training {col} {cant} of {tot}\")\n",
    "    new_values = y_train[col].values.tolist() + [1 for i in range(2640)]\n",
    "    train_gen = DataGenerator(new_X_train, np.array([new_values]).T, 32)\n",
    "    test_gen = DataGenerator(X_test, y_test[[col]], 32)\n",
    "    \n",
    "    final_model.fit(train_gen, validation_data = test_gen, epochs = 500, callbacks = [tf.keras.callbacks.EarlyStopping(patience = 5, restore_best_weights = True)])\n",
    "    final_model.save(f\"./Models/{col}.obj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89bf6a56-f57e-4c55-adc4-ce95154b3e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_models = os.listdir(\"./Animal models v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5875def1-ceba-4800-86af-3b6d318df4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Viuda negra 32 of 32\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "tot = len(l_models)\n",
    "for cant, model in enumerate(l_models):\n",
    "    print(f\"Loading {model.replace('.obj', '')} {cant + 1} of {tot}\")\n",
    "    models.append(tf.keras.models.load_model(f\"./Animal models v2/{model}\"))\n",
    "    clear_output(wait = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fbee1919-1fbb-4d1f-9d52-f9ec97067e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_models = [x.replace('.obj', '') for x in l_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0df88a48-cde5-4d10-b59a-324706c0ae1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, name in zip(models, l_models):\n",
    "    for layer in model.layers:\n",
    "        layer._name = layer.name + name.replace(\" \", \"\").lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "556cf343-6461-4c0a-8a99-a56d3432b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2aca236b-71e3-4f3b-876d-105b3eda9c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_types = {}\n",
    "for key in types:\n",
    "    inverse_types[types[key]] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "414389ac-11f1-4fb1-90ba-59a456d33e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(prediction):\n",
    "    return np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "47556525-23e7-4ac6-8588-0f0e61bb73de",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input((None, None, 3,))\n",
    "resizing = tf.keras.layers.Resizing(224, 224)(inputs)\n",
    "rescaling = tf.keras.layers.Rescaling(1/255)(resizing)\n",
    "concat = tf.concat([m(rescaling, training = False) for m in models], 1)\n",
    "# outputs = tf.keras.layers.Dense(32, activation = \"softmax\")(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3f8f5f99-46f3-485e-a4df-d2edd0698984",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = tf.keras.Model(inputs = inputs, outputs = concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c8622804-9b83-4aba-94d6-2229b534bad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, None, None,  0           []                               \n",
      "                                 3)]                                                              \n",
      "                                                                                                  \n",
      " resizing_2 (Resizing)          (None, 224, 224, 3)  0           ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " rescaling_2 (Rescaling)        (None, 224, 224, 3)  0           ['resizing_2[0][0]']             \n",
      "                                                                                                  \n",
      " model_15 (Functional)          (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_22 (Functional)          (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_23 (Functional)          (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_14 (Functional)          (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_11 (Functional)          (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_30 (Functional)          (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_27 (Functional)          (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_16 (Functional)          (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_2 (Functional)           (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_25 (Functional)          (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_21 (Functional)          (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_28 (Functional)          (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_7 (Functional)           (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_17 (Functional)          (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_3 (Functional)           (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_31 (Functional)          (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_32 (Functional)          (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_8 (Functional)           (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_18 (Functional)          (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_6 (Functional)           (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_13 (Functional)          (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_29 (Functional)          (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_24 (Functional)          (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_10 (Functional)          (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_12 (Functional)          (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_9 (Functional)           (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_5 (Functional)           (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_26 (Functional)          (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_4 (Functional)           (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_19 (Functional)          (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " model_20 (Functional)          (None, 1)            6181994     ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " tf.concat_4 (TFOpLambda)       (None, 32)           0           ['model_15[3][0]',               \n",
      "                                                                  'model_22[3][0]',               \n",
      "                                                                  'model_23[3][0]',               \n",
      "                                                                  'model_14[3][0]',               \n",
      "                                                                  'model_11[3][0]',               \n",
      "                                                                  'model_30[3][0]',               \n",
      "                                                                  'model_27[3][0]',               \n",
      "                                                                  'model_16[3][0]',               \n",
      "                                                                  'model_2[3][0]',                \n",
      "                                                                  'model_25[3][0]',               \n",
      "                                                                  'model_21[3][0]',               \n",
      "                                                                  'model_28[3][0]',               \n",
      "                                                                  'model_7[3][0]',                \n",
      "                                                                  'model_17[3][0]',               \n",
      "                                                                  'model_3[3][0]',                \n",
      "                                                                  'model_31[3][0]',               \n",
      "                                                                  'model_32[3][0]',               \n",
      "                                                                  'model_8[3][0]',                \n",
      "                                                                  'model_18[3][0]',               \n",
      "                                                                  'model_6[3][0]',                \n",
      "                                                                  'model_13[3][0]',               \n",
      "                                                                  'model_29[3][0]',               \n",
      "                                                                  'model_24[3][0]',               \n",
      "                                                                  'model_10[3][0]',               \n",
      "                                                                  'model_12[3][0]',               \n",
      "                                                                  'model_9[3][0]',                \n",
      "                                                                  'model_1[3][0]',                \n",
      "                                                                  'model_5[3][0]',                \n",
      "                                                                  'model_26[3][0]',               \n",
      "                                                                  'model_4[3][0]',                \n",
      "                                                                  'model_19[3][0]',               \n",
      "                                                                  'model_20[3][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 197,823,808\n",
      "Trainable params: 0\n",
      "Non-trainable params: 197,823,808\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c903a6bc-7c7c-4e9d-b278-40f99dbeba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dc98c1bf-0f62-490c-8296-7c35c3f74b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_type = {}\n",
    "for ave in [\"Buho\", \"Cacique\", \"Cisne\", \"Cormoran\", \"Ganso\", \"Paloma\", \"Pato\", \"Pavo\"]:\n",
    "    get_type[ave] = \"Ave\"\n",
    "    \n",
    "for anfibio in [\"Rana\", \"Salamandra\", \"Sapo\"]:\n",
    "    get_type[anfibio] = \"Anfibio\"\n",
    "    \n",
    "for artropodo in [\"Lombriz\", \"Mariposa\", \"Saltamontes\", \"Tarantula\", \"Viuda negra\"]:\n",
    "    get_type[artropodo] = \"Artropodo\"\n",
    "    \n",
    "for mamifero in [\"Caballo\", \"Cabra\", \"Conejo\", \"Elefante\", \"Gato\", \"Leon\", \"Lobo\", \"Oso\", \"Perro\", \"Tigre\"]:\n",
    "    get_type[mamifero] = \"Mamifero\"\n",
    "    \n",
    "for reptil in [\"Camaleon\", \"Cocodrilo\", \"Iguana\", \"Lagarto\", \"Serpiente\", \"Tortuga\"]:\n",
    "    get_type[reptil] = \"Reptil\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c7b7d77-249b-40ea-85aa-79d54b4f81b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f761e5d9-e028-4beb-924c-edd478d48760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openning 1173 of 1174 - image_4229.jpg\n",
      "1/1 [==============================] - 0s 293ms/step\n"
     ]
    }
   ],
   "source": [
    "for i, file in enumerate(test[\"Id\"]):\n",
    "    try:\n",
    "        print(f\"Openning {i} of {len(test)} - {file}\")\n",
    "        v = np.asarray(pl.Image.open(\"./Test/\" + file))\n",
    "        v = v.reshape((1, v.shape[0], v.shape[1], 3))\n",
    "        p = final_model.predict(v)\n",
    "        pred = l_models[get_prediction(p)]\n",
    "        s = f\"{inverse_types[get_type[pred]]} {inverse_types[pred]}\"\n",
    "        predictions.append([file, s])\n",
    "        clear_output(wait  = True)\n",
    "    except:\n",
    "        print(f\"Openning {i} of {len(test)} - {file}\")\n",
    "        v = np.asarray(pl.Image.open(\"./Test/\" + file)).T[0 : 3].T\n",
    "        v = v.reshape((1, v.shape[0], v.shape[1], 3))\n",
    "        p = final_model.predict(v)\n",
    "        pred = l_models[get_prediction(p)]\n",
    "        s = f\"{inverse_types[get_type[pred]]} {inverse_types[pred]}\"\n",
    "        predictions.append([file, s])\n",
    "        clear_output(wait  = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "509fc60b-8d80-4432-a333-70ccbd7b8657",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predictions, columns = [\"Id\", \"Expected\"]).to_csv(\"tercer_intento.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
